% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/back_propagation_training.R
\name{back_propagation_training}
\alias{back_propagation_training}
\alias{plot.BackPropNN_back_propagation_training}
\alias{summary.BackPropNN_back_propagation_training}
\alias{print.BackPropNN_back_propagation_training}
\title{The title of -back_propagation_training-}
\usage{
back_propagation_training(i, h, o, learning_rate, activation_func, data)

\method{plot}{BackPropNN_back_propagation_training}(x)

\method{summary}{BackPropNN_back_propagation_training}(x)

\method{print}{BackPropNN_back_propagation_training}(x)
}
\arguments{
\item{i}{Numeric scalar. Number of input nodes.}

\item{h}{Numeric scalar. Number of hidden nodes.}

\item{o}{Numeric scalar. Number of output nodes.}

\item{learning_rate}{Numeric scalar. Learning rate of the algorithm.}

\item{activation_func}{Character (either "sigmoid" or "ReLU").}

\item{data}{R data frame with X columns and Y labels.}

\item{x}{An object of class \code{BackPropNN_back_propagation_training}.}
}
\value{
A list of class \code{BackPropNN_back_propagation_training}:
}
\description{
Here is a brief description
}
\details{
Computes the weight and bias matrices for the nodes of the neural network with \code{i} # of input nodes, \code{h} # of hidden nodes, and \code{o} # of output nodes.
}
\examples{
set.seed(100)
data <- data.frame(X1 = 1:100, X2 = 2:101, Y = sample(c(0,1), 100, replace=TRUE))
nn_model <- back_propagation_training(i=2, h=2, o=1, learning_rate=0.01,
activation_func="sigmoid", data=data)

}
